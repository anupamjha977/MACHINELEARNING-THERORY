{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11ee23a",
   "metadata": {},
   "source": [
    "1. What is the concept of supervised learning? What is the significance of the name?\n",
    "\n",
    "Supervised learning is a machine learning approach in which a model learns from labeled data to make predictions or decisions. The significance of the name is that the model is \"supervised\" or guided by the labeled data.\n",
    "\n",
    "2. In the hospital sector, offer an example of supervised learning.\n",
    "\n",
    "An example of supervised learning in the hospital sector could be predicting whether a patient has a certain disease based on their symptoms and medical history.\n",
    "\n",
    "3. Give three supervised learning examples.\n",
    "\n",
    "Three examples of supervised learning are:\n",
    "\n",
    "Predicting whether an email is spam or not based on its content and metadata.\n",
    "Recognizing handwritten digits using a dataset of labeled images.\n",
    "Determining whether a customer will buy a product based on their demographic and purchase history\n",
    "\n",
    "4. In supervised learning, what are classification and regression?.\n",
    "\n",
    "Classification involves predicting a categorical label, which means dividing data points into discrete categories based on their features. For instance, classifying emails as spam or not spam, classifying images as dogs or cats, or predicting whether a customer will buy a product or not.\n",
    "\n",
    "Regression involves predicting a continuous numeric value, such as predicting a person's weight or age based on their height, or predicting a stock's price based on historical data.\n",
    "\n",
    "Example of classification in hospital sector: A hospital may use supervised learning to predict whether a patient will develop a certain medical condition based on their symptoms and medical history. The model would be trained on a dataset of previous patients who either developed the condition or did not. Once trained, the model could be used to predict the likelihood of the condition for new patients, allowing doctors to take preventative measures if necessary.\n",
    "\n",
    "Example of regression in hospital sector: A hospital may use supervised learning to predict the length of a patient's stay based on their medical condition and other factors such as age and gender. The model would be trained on a dataset of previous patients with similar conditions and stay lengths. Once trained, the model could be used to predict how long a new patient is likely to stay, helping hospital staff manage resources and plan for patient care.\n",
    "\n",
    "\n",
    "5. Give some popular classification algorithms as examples.\n",
    "\n",
    "Some popular classification algorithms are:\n",
    "\n",
    "Decision Trees\n",
    "\n",
    "Random Forest\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "Support Vector Machines (SVM)\n",
    "\n",
    "k-Nearest Neighbors (kNN)\n",
    "\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad89fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20000, 3072)\n",
      "Target shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "cifar = fetch_openml('CIFAR_10_SMALL', version=1)\n",
    "\n",
    "# Print the shapes of the data and target arrays\n",
    "print('Data shape:', cifar.data.shape)\n",
    "print('Target shape:', cifar.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5375c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(X.shape) # prints (150, 4)\n",
    "print(y.shape) # prints (150,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6454e0",
   "metadata": {},
   "source": [
    "6. Briefly describe the SVM model.\n",
    "\n",
    "The Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression analysis. It finds the best hyperplane that separates the data into different classes. The hyperplane with the largest margin is chosen as the decision boundary.\n",
    "\n",
    "7. In SVM, what is the cost of misclassification?\n",
    "\n",
    "In SVM, the cost of misclassification refers to the penalty for incorrectly classifying a data point. It is a hyperparameter that controls the trade-off between maximizing the margin and minimizing the classification error. A higher cost of misclassification increases the penalty for misclassifying a point, leading to a narrower margin.\n",
    "\n",
    "\n",
    "8. In the SVM model, define Support Vectors.\n",
    "\n",
    "In the SVM model, support vectors are the data points closest to the decision boundary. These points are crucial for defining the hyperplane and determining the margin.\n",
    "\n",
    "\n",
    "9. In the SVM model, define the kernel.\n",
    "\n",
    "In the SVM model, a kernel is a function used to transform the input data into a higher-dimensional space. This allows the SVM to find a linear decision boundary in the transformed space that corresponds to a nonlinear boundary in the original space. Popular kernel functions include linear, polynomial, and radial basis function (RBF) kernels.\n",
    "\n",
    "10. What are the factors that influence SVM's effectiveness?\n",
    "\n",
    "The effectiveness of SVM depends on several factors, including:\n",
    "\n",
    "The choice of kernel function\n",
    "The value of hyperparameters (e.g., cost of misclassification, kernel parameters)\n",
    "The size and quality of the training data\n",
    "The degree of overlap between classes\n",
    "The complexity of the decision boundary\n",
    "\n",
    "11. What are the benefits of using the SVM model?\n",
    "\n",
    "Some benefits of using the SVM model include:\n",
    "Ability to handle high-dimensional data\n",
    "Robustness to outliers\n",
    "Good performance on small datasets\n",
    "Flexibility to use different kernel functions\n",
    "\n",
    "\n",
    "12.  What are the drawbacks of using the SVM model?\n",
    "Some drawbacks of using the SVM model include:\n",
    "Sensitivity to the choice of kernel function and hyperparameters\n",
    "Difficulty in interpreting the model and understanding the decision boundary\n",
    "Computationally expensive for large datasets\n",
    "Limited ability to handle noisy data or overlapping classes\n",
    "\n",
    "13. Notes should be written on\n",
    "\n",
    "1. The kNN algorithm has a validation flaw.\n",
    "\n",
    "2. In the kNN algorithm, the k value is chosen.\n",
    "\n",
    "3. A decision tree with inductive bias\n",
    "Here are some notes on the following topics:\n",
    "\n",
    "The kNN algorithm has a validation flaw: The kNN algorithm is prone to overfitting when the number of neighbors is too small, leading to poor generalization performance. Cross-validation can be used to estimate the optimal number of neighbors.\n",
    "\n",
    "In the kNN algorithm, the k value is chosen: The choice of k can affect the performance of the kNN algorithm. A larger k value can reduce the effect of noise but may cause the boundaries between classes to be less distinct. The optimal k value can be determined using cross-validation.\n",
    "\n",
    "A decision tree with inductive bias: A decision tree algorithm with inductive bias can improve the generalization performance of the model. Inductive bias refers to the assumptions or biases that are built into the model based on prior knowledge or experience. For example, a decision tree with inductive bias may assume that certain features are more important than others when making a decision.\n",
    "\n",
    "14. What are some of the benefits of the kNN algorithm?\n",
    "\n",
    "Some benefits of the kNN algorithm include:\n",
    "\n",
    "Simple and easy to implement\n",
    "Non-parametric, meaning it makes no assumptions about the underlying data distribution\n",
    "Can be used for both classification and regression tasks\n",
    "Robust to noisy data\n",
    "\n",
    "15. What are some of the kNN algorithm's drawbacks?\n",
    "\n",
    "Some drawbacks of the kNN algorithm include:\n",
    "Computationally expensive for large datasets\n",
    "Requires a distance metric to measure similarity between data points\n",
    "Can be sensitive to the choice of k value and distance metric\n",
    "Performs poorly when the feature space is high-dimensional\n",
    "\n",
    "\n",
    "16. Explain the decision tree algorithm in a few words.\n",
    "\n",
    "The decision tree algorithm works by recursively splitting the data into subsets based on the feature values. At each node of the tree, the algorithm selects the feature that maximizes the information gain and splits the data based on that feature. The process is repeated until a stopping criterion is met, such as reaching a maximum tree depth or a minimum number of data points at a node.\n",
    "\n",
    "17. What is the difference between a node and a leaf in a decision tree?\n",
    "\n",
    "In a decision tree, a node represents a split on a feature, while a leaf represents a decision or classification based on the values of the features. In other words, a node represents a question, and a leaf represents an answer.\n",
    "\n",
    "18. What is a decision tree's entropy?\n",
    "\n",
    "Entropy is a measure of the impurity of a set of examples. In the context of decision trees, entropy is used to measure the homogeneity of the labels at a node. A node with low entropy has mostly examples of the same class, while a node with high entropy has roughly equal numbers of examples from different classes.\n",
    "\n",
    "19. In a decision tree, define knowledge gain.\n",
    "\n",
    "Knowledge gain, also known as information gain, is the measure of the improvement in entropy obtained by splitting the data based on a particular feature. The feature with the highest knowledge gain is selected as the split feature at each node.\n",
    "\n",
    "\n",
    "\n",
    "20. Choose three advantages of the decision tree approach and write them down.\n",
    "\n",
    "Three advantages of the decision tree approach are:\n",
    "\n",
    "Decision trees are easy to interpret and explain, making them useful for decision-making.\n",
    "They can handle both categorical and numerical data.\n",
    "They can be used for both classification and regression tasks.\n",
    "\n",
    "\n",
    "21. Make a list of three flaws in the decision tree process.\n",
    "\n",
    "Three flaws of the decision tree approach are:\n",
    "Decision trees can easily overfit the data if the tree is too large or the stopping criteria are not well-chosen.\n",
    "They are sensitive to noise in the data.\n",
    "They can be biased towards features with many values or levels\n",
    "\n",
    "22. Briefly describe the random forest model.\n",
    ".\n",
    "\n",
    "The random forest model is an ensemble learning method that combines multiple decision trees to improve the accuracy and stability of the model. Each tree in the forest is trained on a random subset of the features and a random subset of the data points, creating a diverse set of trees that can capture different aspects of the data. The final prediction is obtained by aggregating the predictions of all the trees in the fores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a14245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "score = rf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365ee4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
