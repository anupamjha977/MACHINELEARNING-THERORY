{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702510f0",
   "metadata": {},
   "source": [
    "A target function, also known as the objective function, is the function in a machine learning model that is being optimized. The target function is used to map input data to output data. It is the function that the learning algorithm is attempting to learn, based on the training data.\n",
    "\n",
    "For example, let's say we want to build a model to predict the price of a house based on various features such as the size, number of bedrooms, and location. The target function in this case would be the function that maps the input features to the house price.\n",
    "\n",
    "The fitness of a target function is typically assessed by a loss function. The loss function is used to measure the difference between the predicted output of the model and the actual output. The goal is to minimize the loss function to improve the performance of the model.\n",
    "\n",
    "Python code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae12b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of target function in linear regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Fit linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Plot data and linear regression line\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, model.predict(X), color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ee36f",
   "metadata": {},
   "source": [
    "\n",
    "Predictive models are used to predict the outcome of a given situation. They are trained on historical data and used to make predictions on new data. Predictive models are used in a variety of fields, including finance, healthcare, and marketing.\n",
    "\n",
    "Descriptive models, on the other hand, are used to describe the relationships between variables in a dataset. They are used to identify patterns and correlations in data, and are often used in exploratory data analysis.\n",
    "\n",
    "Examples of predictive models include linear regression, decision trees, and neural networks. Examples of descriptive models include clustering and principal component analysis.\n",
    "\n",
    "The main difference between predictive and descriptive models is that predictive models are used to make predictions, while descriptive models are used to describe the data.\n",
    "\n",
    "Python code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c4dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Example of predictive modeling with decision trees\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit decision tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Model accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323d2833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYUklEQVR4nO3debRlZXnn8e/PAhoVBJVSkakAUYIIiAVOiYBxAElCnBrQ5ayEOJtOlHRCEE1nObTpdq5FE1p0qUQRQwnlQAuiLQJVIMisJaLUwhYwCIqIDE//sfcll8sddg37nFt3fz9rnXX38J69n/PWrfuc/b77fXeqCknScD1o3AFIksbLRCBJA2cikKSBMxFI0sCZCCRp4DYZdwBra5tttqklS5aMOwxJ2qhcdNFFN1fV4un2bXSJYMmSJaxatWrcYUjSRiXJT2faZ9OQJA2ciUCSBs5EIEkDZyKQpIEzEUjSwJkIJGngTASSNHAmAkkaOBOBJA3cRjeyeH0sOebMcYcwVte979BxhyBpHvKKQJIGzkQgSQNnIpCkgTMRSNLAmQgkaeBMBJI0cCYCSRo4E4EkDZyJQJIGzkQgSQNnIpCkgTMRSNLAmQgkaeBMBJI0cCYCSRo4E4EkDZyJQJIGzkQgSQNnIpCkgTMRSNLAmQgkaeBMBJI0cCYCSRq4XhNBkoOTXJNkdZJjptm/VZKvJLk0yRVJXtNnPJKkB+otESRZBHwcOATYAzgyyR5Tir0JuLKq9gYOBD6UZLO+YpIkPVCfVwT7A6ur6tqq+j1wCnDYlDIFbJkkwBbAvwN39xiTJGmKPhPBdsD1k9bXtNsm+xjwB8ANwGXA26rq3h5jkiRN0WciyDTbasr684FLgMcC+wAfS/KwBxwoOSrJqiSrbrrppg0dpyQNWp+JYA2ww6T17Wm++U/2GuC0aqwGfgLsPvVAVXVCVS2tqqWLFy/uLWBJGqI+E8FKYLckO7cdwEcAy6eU+RnwxwBJHg08Abi2x5gkSVNs0teBq+ruJG8Gvg4sAk6qqiuSHN3uXwa8F/hUkstompLeVVU39xWTJOmBeksEAFW1AlgxZduyScs3AM/rMwZJ0uwcWSxJA2cikKSBMxFI0sCZCCRp4EwEkjRwc941lGRT4C+BZ7WbzgWWVdVdfQYmSRqNLrePfhLYFPhEu/6Kdtvr+wpKkjQ6XRLBfu000RPOTnJpXwFJkkarSx/BPUl2nVhJsgtwT38hSZJGqcsVwd8A5yS5lmYaiJ1oJouTJC0AcyaCqvpmkt1oJoQLcHVV3dl7ZJKkkZgxESR5dlWdneRFU3btmoSqOq3n2CRJIzDbFcEBwNnAn06zrwATgSQtADMmgqo6rl18T1X9ZPK+JDv3GpUkaWS63DX0pWm2nbqhA5EkjcdsfQS7A08EtprST/AwYPO+A5MkjcZsfQRPAP4E2Jr79xP8GnhDjzFJkkZotj6C04HTkzy9qr43wpgkSSPUZUDZ95O8iaaZ6L4moap6bW9RSZJGpktn8WeAxwDPp5l5dHua5iFJ0gLQJRE8rqqOBW6vqpOBQ4En9RuWJGlUuiSCiecO/CrJnsBWwJLeIpIkjVSXPoITkjwc+HtgObAFcGyvUUmSRqbLpHMntovfBnYBSLJTn0FJkkZn1qahJE9P8pIkj2rX90ryOeD/jiQ6SVLvZkwEST4InAS8GDgzyXHAWcAFwG6jCU+S1LfZmoYOBZ5cVb9r+whuAPaqqh+NJjRJ0ijM1jR0R1X9DqCqbgGuMQlI0sIz2xXBrkmWT1pfMnm9qv6sv7AkSaMyWyI4bMr6h/oMRJI0HrNNOnfuKAORJI1Hl5HFkqQFzEQgSQPXOREkeWifgUiSxmPORJDkGUmuBK5q1/dO8oneI5MkjUSXK4L/QfMsgl8CVNWlwLP6DEqSNDqdmoaq6vopm+7p8r4kBye5JsnqJMfMUObAJJckuSKJdypJ0oh1mYb6+iTPACrJZsBbaZuJZpNkEfBx4LnAGmBlkuVVdeWkMlsDnwAOrqqfTUxuJ0kanS5XBEcDbwK2o/mDvk+7Ppf9gdVVdW1V/R44hQcOUnsZcFpV/Qygqm7sGLckaQPp8jyCm4GXr8OxtwMmNymtAZ46pczjgU2TfAvYEvhwVX166oGSHAUcBbDjjjuuQyiSpJl0uWvo5LYJZ2L94UlO6nDsTLOtpqxvAjyFZqbT5wPHJnn8A95UdUJVLa2qpYsXL+5waklSV136CPaqql9NrFTVLUme3OF9a4AdJq1vTzOV9dQyN1fV7cDtSb4N7A38sMPxJUkbQJc+gge1zyMAIMkj6JZAVgK7Jdm57WQ+guaZx5OdDvxRkk2SPISm6WjOjmhJ0obT5Q/6h4Dzkpzarr8U+G9zvamq7k7yZuDrwCLgpKq6IsnR7f5lVXVVkq8BPwDuBU6sqsvX5YNIktZNl87iTye5CDiIpt3/RZNvAZ3jvSuAFVO2LZuy/kHgg50jliRtUF2uCACuBm6ZKJ9kx4lbPiVJG7c5E0GStwDHAb+gGVEcmrt/9uo3NEnSKHS5Ingb8ISq+mXfwUiSRq/LXUPXA7f2HYgkaTy6XBFcC3wryZnAnRMbq+qfe4tKkjQyXRLBz9rXZu1LkrSAdLl99PhRBCJJGo8udw0tBt4JPBHYfGJ7VT27x7gkSSPSpbP4szTjCHYGjgeuo5k+QpK0AHRJBI+sqn8B7qqqc6vqtcDTeo5LkjQiXTqL72p//jzJoTQziG7fX0iSpFHqkgj+MclWwH8BPgo8DHhHr1FJkkamy11DZ7SLt9JMPCdJWkBmTARJ3llVH0jyUR74ZDGq6q29RiZJGonZrggmHhCzahSBSJLGY8ZEUFVfSbII2LOq/maEMUmSRmjW20er6h6ah8tLkhaoLncNfT/JcuCLwO0TG6vqtN6ikiSNTJdE8Ajgl8DkKSUKMBFI0gLQ5fbR14wiEEnSeHSZdG5z4HU8cNK51/YYlyRpRLrMNfQZ4DHA84FzaaaX+HWfQUmSRqdLInhcVR0L3F5VJwOHAk/qNyxJ0qh0SQQTk879KsmewFbAkt4ikiSNVJe7hk5I8nDgWGA5sEW7LElaAGaba+hKmofSnFJVt9D0D+wyqsAkSaMxW9PQkTTf/r+R5IIkb0+y7YjikiSNyIyJoKouraq/rapdgbcBOwEXJDk7yRtGFqEkqVddOoupqvOr6h3AK4GHAx/rNSpJ0sh0GVC2H00z0YtpHlx/As28Q5KkBWC2zuJ/Ag4HbgFOAZ5ZVWtGFZgkaTRmuyK4Ezikqn44qmAkSaM324Npjh9lIJKk8ejUWSxJWrhMBJI0cLN1Fu872xur6uINH44kadRm6yz+UPtzc2ApcCkQYC/gAuAP5zp4koOBDwOLgBOr6n0zlNsPOB84vKpO7Ry9JGm9zTay+KCqOgj4KbBvVS2tqqcATwZWz3XgJIuAjwOHAHsARybZY4Zy7we+vm4fQZK0Prr0EexeVZdNrFTV5cA+Hd63P7C6qq6tqt/TjEU4bJpybwG+BNzY4ZiSpA2sSyK4KsmJSQ5MckCS/wVc1eF92wHXT1pf0267T5LtgBcCy2Y7UJKjkqxKsuqmm27qcGpJUlddEsFrgCtoJp57O3Blu20umWZbTVn/n8C7quqe2Q5UVSe0TVNLFy9e3OHUkqSu5pxrqKp+l2QZsKKqrlmLY68Bdpi0vj1ww5QyS4FTkgBsA7wgyd1V9W9rcR5J0nqY84ogyZ8BlwBfa9f3SbK8w7FXArsl2TnJZsARNE84u09V7VxVS6pqCXAq8EaTgCSNVpemoeNoOn5/BVBVl9DhmcVVdTfwZpq7ga4CvlBVVyQ5OsnR6xivJGkD6/LM4rur6ta2+WatVNUKYMWUbdN2DFfVq9f6BJKk9dYlEVye5GXAoiS7AW8Fzus3LEnSqHRpGnoL8ESaaak/D9xGc/eQJGkB6HLX0G+Bv2tfkqQFpsujKh8P/DVNB/F95avq2f2FJUkalS59BF+kGfl7IjDrwC9J0san611Dn+w9EknSWHTpLP5Kkjcm2TbJIyZevUcmSRqJLlcEr2p//s2kbQXssuHDkSSNWpe7hnYeRSCSpPGY7VGVz66qs5O8aLr9VXVaf2FJkkZltiuCA4CzgT+dZl8BJgJJWgBmTARVdVz7s8uzByRJG6kuncUkOZRmmonNJ7ZV1Xv6CkqSNDpdnkewDDicZs6hAC8Fduo5LknSiHQZR/CMqnolcEtVHQ88nfs/eUyStBHrkgjuaH/+NsljgbsAbymVpAWiSx/BGUm2Bj4IXExzx9CJfQYlSRqdLgPK3tsufinJGcDmVXVrv2FJkkZltgFl0w4ka/c5oEySFojZrgimG0g2wQFlkrRAzDagzIFkkjQAXcYRPDLJR5JcnOSiJB9O8shRBCdJ6l+X20dPAW4CXgy8pF3+1z6DkiSNTpfbRx8x6c4hgH9M8uc9xSNJGrEuVwTnJDkiyYPa138Gzuw7MEnSaHRJBH8BfA64s32dAvxVkl8nua3P4CRJ/esyoGzLUQQiSRqPLncNvW7K+qIkx/UXkiRplLo0Df1xkhVJtk3yJOB8wKsESVogujQNvSzJ4cBlwG+BI6vqu71HJkkaiS5NQ7sBbwO+BFwHvCLJQ3qOS5I0Il2ahr4CHFtVf0HzQPsfASt7jUqSNDJdBpTtX1W3AVRVAR9KsrzfsCRJozLjFUGSdwJU1W1JXjpltxPSSdICMVvT0BGTlv92yr6De4hFkjQGsyWCzLA83bokaSM1WyKoGZanW59WkoOTXJNkdZJjptn/8iQ/aF/nJdm7y3ElSRvObJ3Fe7dzCQV48KR5hQJsPteBkywCPg48F1gDrEyyvKqunFTsJ8ABVXVLkkOAE4CnrsPnkCSto9meULZoPY+9P7C6qq4FSHIKcBhwXyKoqvMmlT8f2H49zylJWktdxhGsq+2A6yetr2m3zeR1wFen25HkqCSrkqy66aabNmCIkqQ+E8F0HcrT9i0kOYgmEbxruv1VdUJVLa2qpYsXL96AIUqSugwoW1drgB0mrW8P3DC1UJK9gBOBQ6rqlz3GI0maRp9XBCuB3ZLsnGQzmnEJ9xuRnGRH4DTgFVX1wx5jkSTNoLcrgqq6O8mbga8Di4CTquqKJEe3+5cB/wA8EvhEEoC7q2ppXzFJkh6oz6YhqmoFsGLKtmWTll8PvL7PGCRJs+uzaUiStBEwEUjSwJkIJGngTASSNHAmAkkaOBOBJA2ciUCSBs5EIEkDZyKQpIEzEUjSwJkIJGngTASSNHAmAkkaOBOBJA2ciUCSBs5EIEkDZyKQpIEzEUjSwJkIJGngTASSNHAmAkkaOBOBJA2ciUCSBs5EIEkDZyKQpIEzEUjSwJkIJGngNhl3ANq4LDnmzHGHMFbXve/QcYcgbXBeEUjSwJkIJGngTASSNHAmAkkaOBOBJA2ciUCSBs5EIEkD5zgCaYQch+E4jPmo1yuCJAcnuSbJ6iTHTLM/ST7S7v9Bkn37jEeS9EC9JYIki4CPA4cAewBHJtljSrFDgN3a11HAJ/uKR5I0vT6bhvYHVlfVtQBJTgEOA66cVOYw4NNVVcD5SbZOsm1V/bzHuCRtpGxa66dprc9EsB1w/aT1NcBTO5TZDrhfIkhyFM0VA8Bvklwzwzm3AW5e14BHYKzx5f2dilmHs+hQh9bfLKy/9bOe9bfTTG/qMxFkmm21DmWoqhOAE+Y8YbKqqpZ2C2/05nt8MP9jNL71Y3zrZ6HG12dn8Rpgh0nr2wM3rEMZSVKP+kwEK4HdkuycZDPgCGD5lDLLgVe2dw89DbjV/gFJGq3emoaq6u4kbwa+DiwCTqqqK5Ic3e5fBqwAXgCsBn4LvGY9Tztn89GYzff4YP7HaHzrx/jWz4KML80NO5KkoXKKCUkaOBOBJA3cRp0IkjwiyVlJftT+fPgM5a5LclmSS5KsGkFc83pqjQ7xHZjk1ra+LknyDyOO76QkNya5fIb9466/ueIbW/0l2SHJOUmuSnJFkrdNU2Zs9dcxvnHW3+ZJLkxyaRvf8dOUGffvX5cY164Oq2qjfQEfAI5pl48B3j9DueuAbUYU0yLgx8AuwGbApcAeU8q8APgqzTiKpwEXjLDOusR3IHDGGP9dnwXsC1w+w/6x1V/H+MZWf8C2wL7t8pbAD+fZ71+X+MZZfwG2aJc3BS4AnjZf6m8tYlyrOtyorwhopqg4uV0+Gfjz8YVyn/um1qiq3wMTU2tMdt/UGlV1PrB1km3nUXxjVVXfBv59liLjrL8u8Y1NVf28qi5ul38NXEUzWn+ysdVfx/jGpq2T37Srm7avqXfUjPv3r0uMa2VjTwSPrnbcQfvzUTOUK+AbSS5qp6vo00zTZqxtmb50PffT20vPryZ54mhC62yc9dfV2OsvyRLgyTTfGCebF/U3S3wwxvpLsijJJcCNwFlVNe/qr0OMsBZ1OO+fR5Dk/wCPmWbX363FYZ5ZVTckeRRwVpKr2291fdhgU2v0pMu5LwZ2qqrfJHkB8G80M8TOF+Osvy7GXn9JtgC+BLy9qm6bunuat4y0/uaIb6z1V1X3APsk2Rr4cpI9q2pyf9DY669DjGtVh/P+iqCqnlNVe07zOh34xcQlWfvzxhmOcUP780bgyzTNI32Z71NrzHnuqrpt4tKzqlYAmybZZkTxdTGvpyYZd/0l2ZTmj+xnq+q0aYqMtf7mim/c9Tcpjl8B3wIOnrJr3vz+zRTj2tbhvE8Ec1gOvKpdfhVw+tQCSR6aZMuJZeB5wLR3e2wg831qjTnjS/KYJGmX96f5PfnliOLrYl5PTTLO+mvP+y/AVVX1zzMUG1v9dYlvzPW3uP2WTZIHA88Brp5SbKy/f11iXNs6nPdNQ3N4H/CFJK8Dfga8FCDJY4ETq+oFwKNpLp2g+byfq6qv9RVQjWdqjQ0d30uAv0xyN3AHcES1tyKMQpLP09z1sE2SNcBxNB1iY6+/jvGNs/6eCbwCuKxtQwb4r8COk+IbZ/11iW+c9bctcHKaB2s9CPhCVZ0xX/7/rkWMa1WHTjEhSQO3sTcNSZLWk4lAkgbORCBJA2cikKSBMxFI0sCZCDR2Se5JM0Pi5Um+mOQhM5Q7bx2PvzTJR9Yjvt/MsP0xSU5J8uMkVyZZkeTx63qe+SDNrJXPGHccGi0TgeaDO6pqn6raE/g9cPTkne390lTVOv2BqqpVVfXW9Q/zfjGFZpT6t6pq16rag+Z++EdvyPOMwYGAiWBgTASab74DPK79ZnpOks8Bl8F/fDNv930ryalJrk7y2UmjKPdLcl6aybYuTLJlW/6Mdv+7k3wmydlpnmPxhnb7Fkm+meTiNM+umGtG1oOAu9rBOwBU1SVV9Z12xOkH2yucy5IcPinuc5N8IckPk7wvycvbOC9Lsmtb7lNJliX5TlvuT9rtmyf5323Z7yc5qN3+6iSnJfla+5k+MBFTkucl+V77ub6YZo6fiWd0HD/p8+6eZhK4o4F3tFdof7Se/5baSGzsI4u1gCTZBDgEmBj5vT+wZ1X9ZJriTwaeSDPHy3eBZya5EPhX4PCqWpnkYTSjKqfai2Ye+YcC309yJs08VS+sqtvSzMlyfpLls4zG3BO4aIZ9LwL2AfYGtgFWJpmY5HBv4A9oprG+lmYE/P5pHtDyFuDtbbklwAHArsA5SR4HvAmgqp6UZHeaGXUnmqL2aevkTuCaJB9tP/vfA8+pqtuTvAv4K+A97Xturqp9k7wR+Ouqen2SZcBvquq/z/DZtACZCDQfPHjSdAPfoZmL5hnAhTMkAdp9awDa9y4BbgV+XlUroZl4q90/9b2nV9UdwB1JzqFJOGcC/5TkWcC9NNMKPxr4f+vwef4Q+Hw7Q+QvkpwL7AfcBqycmJcmyY+Bb7TvuYzmKmPCF6rqXuBHSa4Fdm+P+9H2s12d5KfARCL4ZlXd2h73SmAnYGtgD+C7bR1sBnxv0jkmJny7iCZ5aaBMBJoP7qiqfSZvaP9w3T7Le+6ctHwPze9y6DYd8NQyBbwcWAw8paruSnIdsPksx7iCZj6X6Uw3TfGEyXHfO2n9Xu7//3G6GLsed3J9nFVVR87xnonyGij7CLSQXA08Nsl+AG3/wHR/4A5r29sfSdM5uhLYCrixTQIH0Xyjns3ZwH+a6GNoz7dfkgOAbwOHp3l4yGKaR1teuJaf5aVJHtT2G+wCXNMe9+XtuR5PM1HbNbMc43yaJrPHte95SIe7mn5N8whJDYiJQAtGNY/ePBz4aJJLgbOY/lv9hTRNQecD722fV/FZYGmSVTR/bKdOPTz1XAW8EHhumttHrwDeTdNn8WXgBzTPgz4beGdVrW0T0zXAuTTPxj26qn4HfAJYlOQymr6QV1fVnTMdoKpuAl4NfD7JD9rPu/sc5/0K8EI7i4fF2Uc1KEnezTzvDE3yKZoHj5867lg0DF4RSNLAeUUgSQPnFYEkDZyJQJIGzkQgSQNnIpCkgTMRSNLA/X8AK5pFjkPx/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of descriptive modeling with principal component analysis (PCA)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# Fit PCA model\n",
    "model = PCA()\n",
    "model.fit(X)\n",
    "\n",
    "# Visualize principal components\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(model.n_components_), model.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b59e7",
   "metadata": {},
   "source": [
    "3.Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.\n",
    "Ans:\n",
    "There are various ways to assess a classification model's efficiency, but some of the most commonly used evaluation metrics are:\n",
    "\n",
    "Accuracy: The percentage of correct predictions made by the model.\n",
    "\n",
    "Precision: The percentage of true positives (correctly predicted positive instances) out of all positive predictions made by the model.\n",
    "\n",
    "Recall (also called sensitivity): The percentage of true positives out of all actual positive instances in the dataset.\n",
    "\n",
    "F1 score: A harmonic mean of precision and recall, which takes both into account and can be a good overall measure of the model's performance.\n",
    "\n",
    "Confusion matrix: A table that shows the number of true positives, false positives, true negatives, and false negatives predicted by the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689ae01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707602339181286\n",
      "Precision: 0.963963963963964\n",
      "Recall: 0.9907407407407407\n",
      "F1 score: 0.9771689497716894\n",
      "Confusion matrix:\n",
      "[[ 59   4]\n",
      " [  1 107]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bf513",
   "metadata": {},
   "source": [
    "4:\n",
    "\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "\n",
    "Underfitting occurs when a machine learning model is unable to capture the underlying patterns in the training data, resulting in poor performance on both the training and testing data. This usually occurs when the model is too simple or when the training data is noisy or too complex. The most common reason for underfitting is using a model with too few parameters or features.\n",
    "\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "\n",
    "Overfitting occurs when a machine learning model performs well on the training data but poorly on the testing data. This usually happens when the model is too complex or when it is trained for too long on a limited dataset. Overfitting can also occur when the model is too specific to the training data and fails to generalize well to new data.\n",
    "\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n",
    "\n",
    "The bias-variance trade-off is a key concept in machine learning model fitting. Bias refers to the difference between the expected predictions of the model and the true values, while variance refers to the variability of the model's predictions for different training sets. A model with high bias is likely to underfit the data, while a model with high variance is likely to overfit the data. The goal is to find a model with an optimal balance between bias and variance to achieve good performance on both the training and testing data.\n",
    "\n",
    "Here's an example Python code to demonstrate overfitting and underfitting using a decision tree classifier with different max_depth values on the Iris dataset from scikit-learn:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23221a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (underfitting): 0.648\n",
      "Training accuracy (overfitting): 1.000\n",
      "Testing accuracy (underfitting): 0.711\n",
      "Testing accuracy (overfitting): 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create a decision tree classifier with max_depth=1 (underfitting)\n",
    "clf_underfit = DecisionTreeClassifier(max_depth=1)\n",
    "clf_underfit.fit(X_train, y_train)\n",
    "\n",
    "# create a decision tree classifier with max_depth=10 (overfitting)\n",
    "clf_overfit = DecisionTreeClassifier(max_depth=10)\n",
    "clf_overfit.fit(X_train, y_train)\n",
    "\n",
    "# predict on the training and testing sets\n",
    "y_train_pred_underfit = clf_underfit.predict(X_train)\n",
    "y_train_pred_overfit = clf_overfit.predict(X_train)\n",
    "y_test_pred_underfit = clf_underfit.predict(X_test)\n",
    "y_test_pred_overfit = clf_overfit.predict(X_test)\n",
    "\n",
    "# calculate the accuracy score for each model\n",
    "train_acc_underfit = accuracy_score(y_train, y_train_pred_underfit)\n",
    "train_acc_overfit = accuracy_score(y_train, y_train_pred_overfit)\n",
    "test_acc_underfit = accuracy_score(y_test, y_test_pred_underfit)\n",
    "test_acc_overfit = accuracy_score(y_test, y_test_pred_overfit)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Training accuracy (underfitting): {:.3f}\".format(train_acc_underfit))\n",
    "print(\"Training accuracy (overfitting): {:.3f}\".format(train_acc_overfit))\n",
    "print(\"Testing accuracy (underfitting): {:.3f}\".format(test_acc_underfit))\n",
    "print(\"Testing accuracy (overfitting): {:.3f}\".format(test_acc_overfit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85aa26",
   "metadata": {},
   "source": [
    "5. Is it possible to improve the performance of a machine learning modle?\n",
    "Yes, it is possible to improve the performance of a machine learning model by implementing various techniques, some of which include:\n",
    "\n",
    "Feature engineering: This involves selecting, transforming, and creating new features from the available data to improve the model's performance.\n",
    "\n",
    "Hyperparameter tuning: Adjusting the model's hyperparameters can help improve its performance by finding the optimal values for parameters such as learning rate, regularization, and network architecture.\n",
    "\n",
    "Ensembling: This involves combining multiple models to produce a more accurate prediction.\n",
    "\n",
    "Data augmentation: This involves generating new data from the existing dataset to improve the model's accuracy and robustness.\n",
    "\n",
    "Here is some sample Python code to demonstrate how to use GridSearchCV to perform hyperparameter tuning on a machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff22a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# use GridSearchCV to find the best hyperparameters\n",
    "grid = GridSearchCV(clf, params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# get the best hyperparameters and model accuracy\n",
    "best_params = grid.best_params_\n",
    "accuracy = grid.best_score_\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf7ebd",
   "metadata": {},
   "source": [
    "6: How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?\n",
    "\n",
    "A: Evaluating the success of an unsupervised learning model can be a bit tricky since there are no actual labels to compare the predictions to. However, some common metrics used to measure the success of unsupervised learning models are:\n",
    "\n",
    "Inertia: A measure of how tightly packed the clusters are. It is calculated as the sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "Silhouette Coefficient: A measure of how well a sample is clustered with samples that are similar to it and how poorly it is clustered with samples that are dissimilar to it. The silhouette coefficient ranges from -1 to 1, where values closer to 1 indicate better clustering.\n",
    "\n",
    "Calinski-Harabasz Index: A measure of the ratio between the within-cluster dispersion and the between-cluster dispersion. A higher value indicates better clustering.\n",
    "\n",
    "Here's an example Python code for evaluating the success of a KMeans clustering model using the iris dataset from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b616863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia: 78.851441426146\n",
      "Silhouette Coefficient: 0.5528190123564095\n",
      "Calinski-Harabasz Index: 561.62775662962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# instantiate the KMeans model\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# fit the model to the data\n",
    "kmeans.fit(iris.data)\n",
    "\n",
    "# evaluate the model using inertia, silhouette coefficient, and Calinski-Harabasz index\n",
    "inertia = kmeans.inertia_\n",
    "silhouette_coeff = silhouette_score(iris.data, kmeans.labels_)\n",
    "ch_index = calinski_harabasz_score(iris.data, kmeans.labels_)\n",
    "\n",
    "print(\"Inertia:\", inertia)\n",
    "print(\"Silhouette Coefficient:\", silhouette_coeff)\n",
    "print(\"Calinski-Harabasz Index:\", ch_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a4ba3",
   "metadata": {},
   "source": [
    "7.Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.\n",
    "No, it is not appropriate to use a classification model for numerical data or a regression model for categorical data. This is because classification models are intended to predict categorical variables, while regression models are intended to predict numerical variables.\n",
    "\n",
    "If we try to use a classification model for numerical data, the model would not be able to predict numerical values accurately, and the results would not make sense. Similarly, if we try to use a regression model for categorical data, the model would not be able to predict categorical values accurately, and the results would not be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfc9b4",
   "metadata": {},
   "source": [
    "8: Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?\n",
    "\n",
    "A:\n",
    "\n",
    "Predictive modeling for numerical values typically involves regression models, which aim to predict a continuous numeric output variable based on one or more input variables. Some commonly used regression models include linear regression, polynomial regression, and decision tree regression.\n",
    "\n",
    "In contrast, predictive modeling for categorical values typically involves classification models, which aim to predict a categorical output variable based on one or more input variables. Some commonly used classification models include logistic regression, decision trees, and support vector machines.\n",
    "\n",
    "The main distinction between these two types of predictive modeling is the nature of the output variable being predicted. Numerical predictive modeling aims to predict a continuous numeric output variable, while categorical predictive modeling aims to predict a categorical output variable. This difference influences the choice of modeling techniques and evaluation metrics used in each type of modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9d06e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a k-nearest neighbors classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fb6f3",
   "metadata": {},
   "source": [
    "Q9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
    "\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "\n",
    "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.\n",
    "\n",
    "A9. Based on the given data, we can calculate the following evaluation metrics:\n",
    "\n",
    "True positives (TP) = 15\n",
    "False positives (FP) = 7\n",
    "True negatives (TN) = 75\n",
    "False negatives (FN) = 3\n",
    "\n",
    "Error rate = (FP + FN) / (TP + TN + FP + FN)\n",
    "= (7 + 3) / (15 + 75 + 7 + 3)\n",
    "= 10 / 100\n",
    "= 0.1\n",
    "= 10%\n",
    "\n",
    "Kappa value = (accuracy - random_chance) / (1 - random_chance)\n",
    "= ((TP + TN) / (TP + TN + FP + FN) - ((TP + FN) / (TP + TN + FP + FN)) * ((TP + FP) / (TP + TN + FP + FN))) / (1 - ((TP + FN) / (TP + TN + FP + FN)) * ((TP + FP) / (TP + TN + FP + FN)))\n",
    "= ((15 + 75) / (15 + 75 + 7 + 3) - ((15 + 3) / (15 + 75 + 7 + 3)) * ((15 + 7) / (15 + 75 + 7 + 3))) / (1 - ((15 + 3) / (15 + 75 + 7 + 3)) * ((15 + 7) / (15 + 75 + 7 + 3)))\n",
    "= 0.703\n",
    "\n",
    "\n",
    "Sensitivity (recall) = TP / (TP + FN)\n",
    "= 15 / (15 + 3)\n",
    "= 0.8333\n",
    "= 83.33%\n",
    "\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "= 15 / (15 + 7)\n",
    "= 0.6818\n",
    "= 68.18%\n",
    "\n",
    "\n",
    "F-measure = 2 * (precision * recall) / (precision + recall)\n",
    "= 2 * (0.6818 * 0.8333) / (0.6818 + 0.8333)\n",
    "= 0.7507\n",
    "= 75.07%\n",
    "\n",
    "\n",
    "We can interpret these evaluation metrics as follows:\n",
    "\n",
    "The error rate is 10%, meaning that 10% of the predictions made by the model were incorrect.\n",
    "\n",
    "The Kappa value is 0.703, indicating substantial agreement between the model's predictions and the actual outcomes.\n",
    "\n",
    "The sensitivity is 83.33%, meaning that the model correctly identified 83.33% of the cancerous tumors.\n",
    "\n",
    "The precision is 68.18%, meaning that when the model predicted a tumor to be cancerous, it was correct 68.18% of the time.\n",
    "\n",
    "The F-measure is 75.07%, which is a weighted average of precision and recall and can be a good overall measure of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c1ac4",
   "metadata": {},
   "source": [
    "10. Make quick notes on:\n",
    "         1. The process of holding out\n",
    "         2. Cross-validation by tenfold\n",
    "         3. Adjusting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6279ed",
   "metadata": {},
   "source": [
    "The process of holding out:\n",
    "Holding out is a technique in machine learning where a portion of the dataset is set aside and not used for training the model. Instead, this held-out data is used to evaluate the performance of the model. This technique is commonly used to avoid overfitting and to get an unbiased estimate of the model's performance.\n",
    "\n",
    "Here's an example of holding out a portion of the dataset in Python using scikit-learn:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18b9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "\n",
    "# Evaluate the model on the testing set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cd1bc",
   "metadata": {},
   "source": [
    "Cross-validation by tenfold:\n",
    "Cross-validation is a technique used in machine learning to evaluate the performance of a model. In k-fold cross-validation, the dataset is divided into k subsets, and the model is trained and tested k times. In each iteration, one subset is used for testing, and the remaining k-1 subsets are used for training.\n",
    "\n",
    "Here's an example of performing tenfold cross-validation in Python using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5fd987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Perform tenfold cross-validation\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "# Print the mean score and standard deviation\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5141ed",
   "metadata": {},
   "source": [
    "Adjusting the parameters:\n",
    "In machine learning, adjusting the parameters of a model can significantly impact its performance. One way to find the optimal parameters is through grid search, where a range of parameter values is tested, and the combination that gives the best performance is selected.\n",
    "\n",
    "Here's an example of adjusting the parameters of a random forest classifier in Python usin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70718a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid.fit(iris.data, iris.target)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52146571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
